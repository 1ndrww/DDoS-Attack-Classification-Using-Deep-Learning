{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_RNN_DDoS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow73q3y0k0ab"
      },
      "source": [
        "**Download Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTHxdpmwkQIv",
        "outputId": "71fda813-4029-47a4-9792-a9243bbab4ea"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1OTS726FHnYMqPg6gaz2Ga-WvvhnLv6v1"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OTS726FHnYMqPg6gaz2Ga-WvvhnLv6v1\n",
            "To: /content/ddos_01_12_prep_training.csv\n",
            "15.5MB [00:00, 30.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGiNL2FAk4zr"
      },
      "source": [
        "**Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQPPLxU1kTLg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQVsDE6JlJhD"
      },
      "source": [
        "**Import Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "1ij4VnYmkTP4",
        "outputId": "c7dbc5de-be09-4c1d-b6a2-aa5b024b06ea"
      },
      "source": [
        "df = pd.read_csv(\"./ddos_01_12_prep_training.csv\")\n",
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Inbound</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52380</td>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>443</td>\n",
              "      <td>52380</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>17.897858</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.500000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>23.25</td>\n",
              "      <td>15.5</td>\n",
              "      <td>240.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.00</td>\n",
              "      <td>20.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>245</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>443</td>\n",
              "      <td>52380</td>\n",
              "      <td>6</td>\n",
              "      <td>218</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.000</td>\n",
              "      <td>8.626703e+01</td>\n",
              "      <td>170</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40</td>\n",
              "      <td>4.587156e+03</td>\n",
              "      <td>9174.311927</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>245</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>115366430</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2262086.863</td>\n",
              "      <td>4.120832e+06</td>\n",
              "      <td>9988327</td>\n",
              "      <td>1</td>\n",
              "      <td>115366430</td>\n",
              "      <td>2262086.863</td>\n",
              "      <td>4120831.638</td>\n",
              "      <td>9988327</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.507377e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.666667e+00</td>\n",
              "      <td>1.073087e+00</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>9.613862e+06</td>\n",
              "      <td>2.884856e+05</td>\n",
              "      <td>9988327</td>\n",
              "      <td>9110910</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>68</td>\n",
              "      <td>67</td>\n",
              "      <td>17</td>\n",
              "      <td>109157387</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>4800</td>\n",
              "      <td>0</td>\n",
              "      <td>300</td>\n",
              "      <td>300</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7277159.133</td>\n",
              "      <td>4.248209e+06</td>\n",
              "      <td>14600796</td>\n",
              "      <td>2166672</td>\n",
              "      <td>109157387</td>\n",
              "      <td>7277159.133</td>\n",
              "      <td>4248209.222</td>\n",
              "      <td>14600796</td>\n",
              "      <td>2166672</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>404.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.465773e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>300</td>\n",
              "      <td>300</td>\n",
              "      <td>300.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>318.75</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>404.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4800</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>5.929966e+06</td>\n",
              "      <td>3.774939e+06</td>\n",
              "      <td>10054849</td>\n",
              "      <td>2647210</td>\n",
              "      <td>1.015194e+07</td>\n",
              "      <td>2.795046e+06</td>\n",
              "      <td>14600796</td>\n",
              "      <td>6304546</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Source Port   Destination Port   Protocol  ...   Idle Min   Inbound   label\n",
              "0         52380                443          6  ...          0         0  BENIGN\n",
              "1           443              52380          6  ...          0         1  BENIGN\n",
              "2           443              52380          6  ...          0         1  BENIGN\n",
              "3             0                  0          0  ...    9110910         0  BENIGN\n",
              "4            68                 67         17  ...    6304546         0  BENIGN\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SC9F5ZZlbnH"
      },
      "source": [
        "**Encoding Label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ2LUhG1kTTm",
        "outputId": "af8c84c0-17e9-4698-fd3b-50db56a6ba26"
      },
      "source": [
        "df = df.sample(n = 52318, replace = False, random_state= 32)\n",
        "df['label'] = df['label'].map({'BENIGN' : 0, 'DDOS' : 1})\n",
        "df.label.value_counts()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    26892\n",
              "0    25426\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eprdkDXBlnBd"
      },
      "source": [
        "**Split Input & Output Feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTJf5O5fkTXS",
        "outputId": "b984162e-71d0-48a2-e63c-8ad5d2051d9c"
      },
      "source": [
        "X = df.drop(columns=\"label\")\n",
        "y = df['label']\n",
        "X.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52318, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjzBZ7Z0swYq"
      },
      "source": [
        "**Standard Scaler**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAK0x6XNsail"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "scalar = StandardScaler(copy=False, with_mean=False, with_std=False)\n",
        "scalar.fit(X)\n",
        "X = scalar.transform(X)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz9SKO5bmC04"
      },
      "source": [
        "**Feature Selection Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6klTI--kTaz"
      },
      "source": [
        "# def feature_selection_IG(n_feature, df) :\n",
        "#   list_select_attribute = []\n",
        "#   list_feature = [2,1,40,54,11,53,41,10,39,9,7,64,19,79,17,38,4,37,18,36,65,6,35,56,29,26,27,43,42,30,67,52,70,13,8,66,15,55,24,21,22,68,14,49,63,5,12,69,23,25,20,3,28,50,16,74,73,71,31,46,75,77,78,76,72,45,48,60,59,61,57,58,62,51,33,34,44,47,32]\n",
        "  \n",
        "#   for x in list_feature:\n",
        "#     list_select_attribute.append(x-1)\n",
        "\n",
        "#   feature_selection = list_select_attribute[0:n_feature]\n",
        "#   feature_selection\n",
        "#   df= df.iloc[: ,feature_selection]\n",
        "#   return df\n",
        "# X = feature_selection_IG(40,X)\n",
        "# X\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bBgxf03s7P8"
      },
      "source": [
        "**Feature Extraction PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FpfInNFs3s3"
      },
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "# import matplotlib.pyplot as plt\n",
        "# pca  = PCA(n_components = 40, whiten = True)\n",
        "# X = pca.fit_transform(X)\n",
        "# X.shape"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fJnspp2m2wb"
      },
      "source": [
        "**Custom Dataset RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKEuFVslm1Ce"
      },
      "source": [
        "from numpy import array\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X= list()\n",
        "  for i in range(len(sequence)):\n",
        "  # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence)-1:\n",
        "       break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x = sequence[i:end_ix]\n",
        "    X.append(seq_x)\n",
        "  return array(X)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = X\n",
        "# choose a number of time steps\n",
        "n_steps = 50\n",
        "# transform input from [samples, features] to [samples, timesteps, features]\n",
        "#X_ = X_.reshape((X_.shape[0], X_.shape[1], 79))\n",
        "# split into samples\n",
        "X_= split_sequence(raw_seq, n_steps)\n",
        "Y = y[n_steps-1:len(df)-1]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRXxi_8vte70"
      },
      "source": [
        "**Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD4Esp0vpWt5"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_, Y ,test_size = 0.3,shuffle=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRV_mWg9tk73"
      },
      "source": [
        "**Import Packages Tensorflow Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1JxGzM5tplN"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "import seaborn as sns; sns.set()\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_99DZulttQA"
      },
      "source": [
        "**Early Stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8o9cWomtvn_"
      },
      "source": [
        "early_stopping_monitor = EarlyStopping(patience=30)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzyZDOsTuRqx"
      },
      "source": [
        "**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfb-pBBut3z5"
      },
      "source": [
        "def create_baseline():\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(128))\n",
        "    model.add(Dense(32))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(16)) \n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(8))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69lcGqU_t3_O"
      },
      "source": [
        "model = create_baseline()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-cJTavcujq4",
        "outputId": "a94fff86-884d-4adc-c443-5b964ac9f7da"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train, Y_train, epochs = 50, callbacks = [early_stopping_monitor], batch_size =100, validation_split=0.2, verbose = 1)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "293/293 [==============================] - 13s 39ms/step - loss: 0.3073 - accuracy: 0.8816 - val_loss: 0.2324 - val_accuracy: 0.9124\n",
            "Epoch 2/50\n",
            "293/293 [==============================] - 11s 38ms/step - loss: 0.2536 - accuracy: 0.9073 - val_loss: 0.2275 - val_accuracy: 0.9165\n",
            "Epoch 3/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2342 - accuracy: 0.9175 - val_loss: 0.2125 - val_accuracy: 0.9212\n",
            "Epoch 4/50\n",
            "293/293 [==============================] - 13s 46ms/step - loss: 0.2327 - accuracy: 0.9220 - val_loss: 0.2192 - val_accuracy: 0.9266\n",
            "Epoch 5/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2304 - accuracy: 0.9210 - val_loss: 0.2238 - val_accuracy: 0.9274\n",
            "Epoch 6/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2250 - accuracy: 0.9226 - val_loss: 0.2182 - val_accuracy: 0.9261\n",
            "Epoch 7/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2232 - accuracy: 0.9227 - val_loss: 0.2150 - val_accuracy: 0.9240\n",
            "Epoch 8/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2213 - accuracy: 0.9243 - val_loss: 0.2106 - val_accuracy: 0.9262\n",
            "Epoch 9/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2173 - accuracy: 0.9265 - val_loss: 0.2062 - val_accuracy: 0.9278\n",
            "Epoch 10/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2184 - accuracy: 0.9260 - val_loss: 0.2196 - val_accuracy: 0.9255\n",
            "Epoch 11/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2190 - accuracy: 0.9260 - val_loss: 0.2468 - val_accuracy: 0.9243\n",
            "Epoch 12/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2218 - accuracy: 0.9245 - val_loss: 0.2165 - val_accuracy: 0.9296\n",
            "Epoch 13/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2190 - accuracy: 0.9255 - val_loss: 0.2099 - val_accuracy: 0.9274\n",
            "Epoch 14/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2142 - accuracy: 0.9271 - val_loss: 0.2062 - val_accuracy: 0.9288\n",
            "Epoch 15/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2202 - accuracy: 0.9259 - val_loss: 0.2131 - val_accuracy: 0.9257\n",
            "Epoch 16/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2223 - accuracy: 0.9253 - val_loss: 0.2136 - val_accuracy: 0.9285\n",
            "Epoch 17/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2208 - accuracy: 0.9250 - val_loss: 0.2168 - val_accuracy: 0.9255\n",
            "Epoch 18/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2186 - accuracy: 0.9252 - val_loss: 0.2146 - val_accuracy: 0.9268\n",
            "Epoch 19/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2180 - accuracy: 0.9253 - val_loss: 0.2117 - val_accuracy: 0.9273\n",
            "Epoch 20/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2137 - accuracy: 0.9267 - val_loss: 0.2107 - val_accuracy: 0.9287\n",
            "Epoch 21/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2165 - accuracy: 0.9266 - val_loss: 0.2091 - val_accuracy: 0.9278\n",
            "Epoch 22/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2154 - accuracy: 0.9265 - val_loss: 0.2160 - val_accuracy: 0.9281\n",
            "Epoch 23/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2138 - accuracy: 0.9264 - val_loss: 0.2076 - val_accuracy: 0.9284\n",
            "Epoch 24/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2105 - accuracy: 0.9270 - val_loss: 0.2069 - val_accuracy: 0.9288\n",
            "Epoch 25/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2111 - accuracy: 0.9278 - val_loss: 0.2072 - val_accuracy: 0.9291\n",
            "Epoch 26/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2114 - accuracy: 0.9283 - val_loss: 0.2098 - val_accuracy: 0.9281\n",
            "Epoch 27/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2119 - accuracy: 0.9280 - val_loss: 0.2081 - val_accuracy: 0.9291\n",
            "Epoch 28/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2129 - accuracy: 0.9275 - val_loss: 0.2176 - val_accuracy: 0.9280\n",
            "Epoch 29/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2136 - accuracy: 0.9273 - val_loss: 0.2171 - val_accuracy: 0.9285\n",
            "Epoch 30/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2136 - accuracy: 0.9277 - val_loss: 0.2078 - val_accuracy: 0.9300\n",
            "Epoch 31/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2124 - accuracy: 0.9286 - val_loss: 0.2120 - val_accuracy: 0.9285\n",
            "Epoch 32/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2111 - accuracy: 0.9292 - val_loss: 0.2084 - val_accuracy: 0.9289\n",
            "Epoch 33/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2108 - accuracy: 0.9293 - val_loss: 0.2149 - val_accuracy: 0.9306\n",
            "Epoch 34/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2112 - accuracy: 0.9282 - val_loss: 0.2062 - val_accuracy: 0.9281\n",
            "Epoch 35/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2093 - accuracy: 0.9296 - val_loss: 0.2162 - val_accuracy: 0.9291\n",
            "Epoch 36/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2121 - accuracy: 0.9293 - val_loss: 0.2161 - val_accuracy: 0.9302\n",
            "Epoch 37/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2137 - accuracy: 0.9277 - val_loss: 0.2135 - val_accuracy: 0.9278\n",
            "Epoch 38/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2120 - accuracy: 0.9289 - val_loss: 0.2098 - val_accuracy: 0.9303\n",
            "Epoch 39/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2111 - accuracy: 0.9289 - val_loss: 0.2173 - val_accuracy: 0.9284\n",
            "Epoch 40/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2097 - accuracy: 0.9289 - val_loss: 0.2073 - val_accuracy: 0.9287\n",
            "Epoch 41/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2141 - accuracy: 0.9285 - val_loss: 0.2085 - val_accuracy: 0.9295\n",
            "Epoch 42/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2121 - accuracy: 0.9295 - val_loss: 0.2097 - val_accuracy: 0.9285\n",
            "Epoch 43/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2103 - accuracy: 0.9301 - val_loss: 0.2026 - val_accuracy: 0.9310\n",
            "Epoch 44/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2123 - accuracy: 0.9298 - val_loss: 0.2072 - val_accuracy: 0.9307\n",
            "Epoch 45/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2122 - accuracy: 0.9287 - val_loss: 0.2105 - val_accuracy: 0.9311\n",
            "Epoch 46/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2122 - accuracy: 0.9288 - val_loss: 0.2073 - val_accuracy: 0.9307\n",
            "Epoch 47/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2098 - accuracy: 0.9293 - val_loss: 0.2099 - val_accuracy: 0.9314\n",
            "Epoch 48/50\n",
            "293/293 [==============================] - 12s 39ms/step - loss: 0.2115 - accuracy: 0.9290 - val_loss: 0.2024 - val_accuracy: 0.9283\n",
            "Epoch 49/50\n",
            "293/293 [==============================] - 11s 39ms/step - loss: 0.2088 - accuracy: 0.9281 - val_loss: 0.2038 - val_accuracy: 0.9311\n",
            "Epoch 50/50\n",
            "293/293 [==============================] - 12s 40ms/step - loss: 0.2106 - accuracy: 0.9294 - val_loss: 0.2131 - val_accuracy: 0.9300\n",
            "--- 623.2125878334045 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYgo7qKBwyS-"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu5B63jEuuPk",
        "outputId": "8d2fc048-16ca-4510-a84e-fd1658f2fdeb"
      },
      "source": [
        "model.save('RNN')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: RNN/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH82niSfw5ZY"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0xrA2qAw3_6"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('RNN')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kkv7_OSxDgy"
      },
      "source": [
        "**Predict Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "EAMne8YnxFxw",
        "outputId": "10616cd5-b840-4dcc-d547-55688f9da367"
      },
      "source": [
        "predict = model.predict(X_test, verbose=1)\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "predictn = predict.flatten().round()\n",
        "predictn = predictn.tolist()\n",
        "Y_testn = Y_test.tolist()\n",
        "for i in range(len(Y_testn)):\n",
        "  if predictn[i]==1 and Y_testn[i]==1:\n",
        "    tp+=1\n",
        "  elif predictn[i]==0 and Y_testn[i]==0:\n",
        "    tn+=1\n",
        "  elif predictn[i]==0 and Y_testn[i]==1:\n",
        "    fp+=1\n",
        "  elif predictn[i]==1 and Y_testn[i]==0:\n",
        "    fn+=1\n",
        "\n",
        "to_heat_map =[[tp,fp],[fn,tn]]\n",
        "to_heat_map = pd.DataFrame(to_heat_map, index = [\"Attack\",\"Normal\"],columns = [\"Attack\",\"Normal\"])\n",
        "ax = sns.heatmap(to_heat_map,annot=True, fmt=\"d\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 4s 7ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63_rzw0txKU_",
        "outputId": "2d0ececd-52a9-4b46-c231-bd0c6df2e8ae"
      },
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 92.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncn9Hh3Rx833"
      },
      "source": [
        "**Testing Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pmA6jmbx73T"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1Db7O9WB99VfS0_LFR2Gm9WSzuGhQasNH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYKXncQx76z"
      },
      "source": [
        "!unzip './DATASET_TESTING.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzIQtlneyNhm"
      },
      "source": [
        "**Import Testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WltdCGxQx7-A"
      },
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_csv(\"./DATASET_TESTING/LDAP_TEST.csv\")\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dr-4L0DyTRs"
      },
      "source": [
        "df2['label'] = df2['label'].map({'BENIGN' : 0, 'DDOS' : 1})\n",
        "X2 = df2.drop(columns=\"label\")\n",
        "y2 = df2['label']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntnlSsESyz_V"
      },
      "source": [
        "**Standard Scaler**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOhoA8MyyIU"
      },
      "source": [
        "scalar = StandardScaler(copy=False, with_mean=False, with_std=False)\n",
        "scalar.fit(X2)\n",
        "X2 = scalar.transform(X2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_z5obhWya3f"
      },
      "source": [
        "**Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO_DNLC2ydy3"
      },
      "source": [
        "\n",
        "def feature_selection_IG(n_feature, df) :\n",
        "  list_select_attribute = []\n",
        "  list_feature = [2,1,40,54,11,53,41,10,39,9,7,64,19,79,17,38,4,37,18,36,65,6,35,56,29,26,27,43,42,30,67,52,70,13,8,66,15,55,24,21,22,68,14,49,63,5,12,69,23,25,20,3,28,50,16,74,73,71,31,46,75,77,78,76,72,45,48,60,59,61,57,58,62,51,33,34,44,47,32]\n",
        "  \n",
        "  for x in list_feature:\n",
        "    list_select_attribute.append(x-1)\n",
        "\n",
        "  feature_selection = list_select_attribute[0:n_feature]\n",
        "  feature_selection\n",
        "  df= df.iloc[: ,feature_selection]\n",
        "  return df\n",
        "X2_ = feature_selection_IG(40,X2)\n",
        "X2_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kMBm1yvzJeo"
      },
      "source": [
        "**Feature Extraction PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWVkvGNYyxLT"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "pca  = PCA(n_components = 40, whiten = True)\n",
        "X2_ = pca.fit_transform(X2)\n",
        "X2_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJj5wiCizZJ3"
      },
      "source": [
        "**Custom Dataset RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2iRVCzezb0k"
      },
      "source": [
        "from numpy import array\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X= list()\n",
        "  for i in range(len(sequence)):\n",
        "  # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence)-1:\n",
        "       break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x = sequence[i:end_ix]\n",
        "    X.append(seq_x)\n",
        "  return array(X)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = X2_\n",
        "# choose a number of time steps\n",
        "n_steps = 50\n",
        "# transform input from [samples, features] to [samples, timesteps, features]\n",
        "#X_ = X_.reshape((X_.shape[0], X_.shape[1], 79))\n",
        "# split into samples\n",
        "X_2= split_sequence(raw_seq, n_steps)\n",
        "Y2 = y2[n_steps-1:len(df2)-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL26TI-Y2-bX"
      },
      "source": [
        "**Testing Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk92U8C2zgCG"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "scores = model.evaluate(X_2, Y2, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwnXY5zu2QA2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}